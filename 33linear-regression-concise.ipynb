{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"33linear-regression-concise.ipynb","provenance":[{"file_id":"https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/chapter_linear-networks/linear-regression-concise.ipynb","timestamp":1597540367190}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Y4Tex7ss0kKq","colab_type":"text"},"source":["The following additional libraries are needed to run this\n","notebook. Note that running on Colab is experimental, please report a Github\n","issue if you have any problem."]},{"cell_type":"code","metadata":{"id":"w8s7AdY50kKr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":918},"executionInfo":{"status":"ok","timestamp":1597551059484,"user_tz":420,"elapsed":6241,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"903d18b5-f75a-40ba-fbe8-dc39f19f4865"},"source":["!pip install d2l==0.14.3\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting d2l==0.14.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/c1/c39e1c7571effc1738bdd7c846b4a9a8ad7c58f672f05ca4cbd8367eda57/d2l-0.14.3-py3-none-any.whl (53kB)\n","\r\u001b[K     |██████▏                         | 10kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.8MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from d2l==0.14.3) (1.0.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l==0.14.3) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from d2l==0.14.3) (1.18.5)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l==0.14.3) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.14.3) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.14.3) (2018.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.14.3) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.14.3) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.14.3) (2.4.7)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.3) (4.7.5)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.3) (4.10.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.3) (5.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.3) (5.6.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.3) (5.3.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.3) (7.5.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->d2l==0.14.3) (1.15.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.3) (2.1.3)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.3) (0.2.0)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.3) (19.0.2)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.3) (4.3.3)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.3) (1.9.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.3) (4.6.3)\n","Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.3) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.14.3) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.14.3) (5.5.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.14.3) (1.0.18)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.3) (0.4.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.3) (0.6.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.3) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.3) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.3) (1.4.2)\n","Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.3) (5.0.7)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.3) (2.11.2)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.3) (3.1.5)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.14.3) (0.8.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.14.3) (1.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.14.3) (3.5.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->qtconsole->jupyter->d2l==0.14.3) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.3) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.3) (49.2.0)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.3) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.3) (0.8.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.14.3) (0.2.5)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter->d2l==0.14.3) (2.6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter->d2l==0.14.3) (1.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.14.3) (20.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.14.3) (0.5.1)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.14.3) (0.6.0)\n","Installing collected packages: d2l\n","Successfully installed d2l-0.14.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"gQy5oxEz0kKw","colab_type":"text"},"source":["# Concise Implementation of Linear Regression\n",":label:`sec_linear_concise`\n","\n","Broad and intense interest in deep learning for the past several years\n","has inspired companies, academics, and hobbyists\n","to develop a variety of mature open source frameworks\n","for automating the repetitive work of implementing\n","gradient-based learning algorithms.\n","In :numref:`sec_linear_scratch`, we relied only on\n","(i) tensors for data storage and linear algebra;\n","and (ii) auto differentiation for calculating gradients.\n","In practice, because data iterators, loss functions, optimizers,\n","and neural network layers\n","are so common, modern libraries implement these components for us as well.\n","\n","In this section, we will show you how to implement\n","the linear regression model from :numref:`sec_linear_scratch`\n","concisely by using high-level APIs of deep learning frameworks.\n","\n","\n","## Generating the Dataset\n","\n","To start, we will generate the same dataset as in :numref:`sec_linear_scratch`.\n"]},{"cell_type":"code","metadata":{"origin_pos":3,"tab":["tensorflow"],"id":"30e1MHaW0kKx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597551061236,"user_tz":420,"elapsed":7981,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["from d2l import tensorflow as d2l\n","import numpy as np\n","import tensorflow as tf"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"origin_pos":4,"tab":["tensorflow"],"id":"6-C0es3J0kK0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597551061238,"user_tz":420,"elapsed":7976,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["true_w = tf.constant([2, -3.4])\n","true_b = 4.2\n","#d2l's own implementation obtaining synthetic data\n","features, labels = d2l.synthetic_data(true_w, true_b, 1000)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":5,"id":"ou6WbePS0kK2","colab_type":"text"},"source":["## Reading the Dataset\n","\n","Rather than rolling our own iterator,\n","we can call upon the existing API in a framework to read data.\n","We pass in `features` and `labels` as arguments and specify `batch_size`\n","when instantiating a data iterator object.\n","Besides, the boolean value `is_train`\n","indicates whether or not\n","we want the data iterator object to shuffle the data\n","on each epoch (pass through the dataset).\n"]},{"cell_type":"markdown","metadata":{"id":"IfTrOiAJ7Hy4","colab_type":"text"},"source":["[https://www.tensorflow.org/guide/data](https://www.tensorflow.org/guide/data)"]},{"cell_type":"code","metadata":{"id":"XPxGWigbdR1c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597551061239,"user_tz":420,"elapsed":7668,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["dset = tf.data.Dataset.from_tensor_slices((features, labels))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_Ptes4kdrRT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597551247696,"user_tz":420,"elapsed":794,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["fel = list(dset.as_numpy_iterator())"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXSRyttzeZD_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597551275861,"user_tz":420,"elapsed":773,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"cbb4afed-31e2-406c-fae8-130c56dbd9d7"},"source":["print(fel[0])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(array([-0.89466023, -0.6338276 ], dtype=float32), array([4.566094], dtype=float32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ldbkqcwLfCmp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597551568917,"user_tz":420,"elapsed":752,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"10155770-86d3-48e9-fbcc-c01eaae320ff"},"source":["fset = tf.data.Dataset.from_tensor_slices(features)\n","flist = list(fset.as_numpy_iterator())\n","print(flist[0])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[-0.89466023 -0.6338276 ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TTMdH3SZfsOO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597551655929,"user_tz":420,"elapsed":791,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["lset = tf.data.Dataset.from_tensor_slices(labels)\n","llist = list(lset.as_numpy_iterator())"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"gADX-IrNf8Nw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597551673753,"user_tz":420,"elapsed":762,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"d89aba24-4fa2-4e83-9d18-5d563d642208"},"source":["print(llist[0])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[4.566094]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jXMWdtnpgVJQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597553654820,"user_tz":420,"elapsed":1102,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"e02508ac-1b6b-4ba2-c584-5b38b657f445"},"source":["print(type(features))\n","print(type(labels))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["<class 'tensorflow.python.framework.ops.EagerTensor'>\n","<class 'tensorflow.python.framework.ops.EagerTensor'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jsFQ3lg2wGKb","colab_type":"text"},"source":["Every time `load_array` is called, if `is_train` is set to `True`, the dataset gets shuffled before returning the dataset."]},{"cell_type":"code","metadata":{"origin_pos":8,"tab":["tensorflow"],"id":"VZ-pkEjZ0kK3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597554409723,"user_tz":420,"elapsed":909,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["#data_arrays is a tuple of features and labels\n","def load_array(data_arrays, batch_size, is_train=True):  #@save\n","    \"\"\"Construct a TensorFlow data iterator.\"\"\"\n","    #basically takes 10 (batch size) rows of features and labels\n","    #and represents them as a \"dataset\"\n","    dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\n","    if is_train:\n","        #shuffles the data by sampling entries (buffer_size)\n","        #from a 1000 entry buffer. Everytime an entry is sampled, the\n","        #entry's place is taken by a new entry from outside the buffer if any\n","        dataset = dataset.shuffle(buffer_size=1000)\n","    dataset = dataset.batch(batch_size)\n","    return dataset"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"origin_pos":9,"tab":["tensorflow"],"id":"QSLbme-p0kK5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597554411367,"user_tz":420,"elapsed":817,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["batch_size = 10\n","data_iter = load_array((features, labels), batch_size)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ks1oxk1HrftU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1597555193447,"user_tz":420,"elapsed":786,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"21a27bf4-d416-4583-caec-d1bc2c292eab"},"source":["#practice\n","dlist = list(data_iter.as_numpy_iterator())\n","dlist[0]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[ 0.70862526,  1.2192032 ],\n","        [ 0.7843208 , -0.2750216 ],\n","        [-0.6846534 ,  0.50200665],\n","        [ 1.6817191 ,  1.2582612 ],\n","        [ 1.6341274 ,  0.30543736],\n","        [ 0.3761744 , -0.01750514],\n","        [-1.3755399 , -0.52630264],\n","        [-0.2920044 , -0.07757249],\n","        [ 0.01635778, -1.5822426 ],\n","        [-0.46637008,  0.9045051 ]], dtype=float32), array([[1.4664328 ],\n","        [6.715562  ],\n","        [1.1387159 ],\n","        [3.2866995 ],\n","        [6.4292264 ],\n","        [5.001237  ],\n","        [3.2359211 ],\n","        [3.8777082 ],\n","        [9.597429  ],\n","        [0.19003361]], dtype=float32))"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"WnRYJbROs7Gh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597555069917,"user_tz":420,"elapsed":507,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"3106f3ce-d09f-4cbe-b863-0faa49e02c08"},"source":["type(data_iter)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.data.ops.dataset_ops.BatchDataset"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"origin_pos":10,"id":"uUi53scs0kK7","colab_type":"text"},"source":["Now we can use `data_iter` in much the same way as we called\n","the `data_iter` function in :numref:`sec_linear_scratch`.\n","To verify that it is working, we can read and print\n","the first minibatch of examples.\n","Comparing with :numref:`sec_linear_scratch`,\n","here we use `iter` to construct a Python iterator and use `next` to obtain the first item from the iterator.\n"]},{"cell_type":"code","metadata":{"origin_pos":11,"tab":["tensorflow"],"id":"0HUGT9N60kK8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1597554440248,"user_tz":420,"elapsed":595,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"84ae3ed8-c523-4299-b6c2-c156e626c6b4"},"source":["next(iter(data_iter))"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n"," array([[-0.19441114,  0.49152496],\n","        [-0.702771  ,  1.2664042 ],\n","        [-1.1907264 , -0.9990662 ],\n","        [ 0.07564203,  0.8183015 ],\n","        [ 0.46178213,  0.67119825],\n","        [ 0.14035554, -0.87641287],\n","        [ 1.6341274 ,  0.30543736],\n","        [-0.00917123, -0.5065995 ],\n","        [ 1.3714517 , -0.09719807],\n","        [-1.3521336 , -0.3148818 ]], dtype=float32)>,\n"," <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n"," array([[ 2.1520443],\n","        [-1.510767 ],\n","        [ 5.2170906],\n","        [ 1.5546464],\n","        [ 2.8351681],\n","        [ 7.4624496],\n","        [ 6.4292264],\n","        [ 5.8878107],\n","        [ 7.258221 ],\n","        [ 2.566607 ]], dtype=float32)>)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"origin_pos":12,"id":"rvK9npXd0kLC","colab_type":"text"},"source":["## Defining the Model\n","\n","When we implemented linear regression from scratch\n","in :numref:`sec_linear_scratch`,\n","we defined our model parameters explicitly\n","and coded up the calculations to produce output\n","using basic linear algebra operations.\n","You *should* know how to do this.\n","But once your models get more complex,\n","and once you have to do this nearly every day,\n","you will be glad for the assistance.\n","The situation is similar to coding up your own blog from scratch.\n","Doing it once or twice is rewarding and instructive,\n","but you would be a lousy web developer\n","if every time you needed a blog you spent a month\n","reinventing the wheel.\n","\n","For standard operations, we can use a framework's predefined layers,\n","which allow us to focus especially\n","on the layers used to construct the model\n","rather than having to focus on the implementation.\n","We will first define a model variable `net`,\n","which will refer to an instance of the `Sequential` class.\n","The `Sequential` class defines a container\n","for several layers that will be chained together.\n","Given input data, a `Sequential` instance passes it through\n","the first layer, in turn passing the output\n","as the second layer's input and so forth.\n","In the following example, our model consists of only one layer,\n","so we do not really need `Sequential`.\n","But since nearly all of our future models\n","will involve multiple layers,\n","we will use it anyway just to familiarize you\n","with the most standard workflow.\n","\n","Recall the architecture of a single-layer network as shown in :numref:`fig_single_neuron`.\n","The layer is said to be *fully-connected*\n","because each of its inputs is connected to each of its outputs\n","by means of a matrix-vector multiplication.\n"]},{"cell_type":"markdown","metadata":{"origin_pos":15,"tab":["tensorflow"],"id":"ffhjPvLc0kLC","colab_type":"text"},"source":["In Keras, the fully-connected layer is defined in the `Dense` class. Since we only want to generate a single scalar output, we set that number to 1.\n","\n","It is worth noting that, for convenience,\n","Keras does not require us to specify\n","the input shape for each layer.\n","So here, we do not need to tell Keras\n","how many inputs go into this linear layer.\n","When we first try to pass data through our model,\n","e.g., when we execute `net(X)` later,\n","Keras will automatically infer the number of inputs to each layer.\n","We will describe how this works in more detail later.\n"]},{"cell_type":"code","metadata":{"origin_pos":18,"tab":["tensorflow"],"id":"Fs_mC6nI0kLD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597557531544,"user_tz":420,"elapsed":793,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["# `keras` is the high-level API for TensorFlow\n","#net basically represents the entire network. Layers are added sequentially to it\n","net = tf.keras.Sequential()\n","\n","\"\"\"\n","Dense implements the operation: output = activation(dot(input, kernel) + bias)\n","where activation is the element-wise activation function passed as the activation \n","argument, kernel is a weights matrix created by the layer, and bias is a bias \n","vector created by the layer (only applicable if use_bias is True).\n","\"\"\"\n","#basically (X*w)+b where X is the features\n","net.add(tf.keras.layers.Dense(1))"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":19,"id":"CSgyOmCq0kLG","colab_type":"text"},"source":["## Initializing Model Parameters\n","\n","Before using `net`, we need to initialize the model parameters,\n","such as the weights and bias in the linear regression model.\n","Deep learning frameworks often have a predefined way to initialize the parameters.\n","Here we specify that each weight parameter\n","should be randomly sampled from a normal distribution\n","with mean 0 and standard deviation 0.01.\n","The bias parameter will be initialized to zero.\n"]},{"cell_type":"markdown","metadata":{"origin_pos":22,"tab":["tensorflow"],"id":"TTfxHHqY0kLG","colab_type":"text"},"source":["The `initializers` module in TensorFlow provides various methods for model parameter initialization. The easiest way to specify the initialization method in Keras is when creating the layer by specifying `kernel_initializer`. Here we recreate `net` again.\n"]},{"cell_type":"code","metadata":{"origin_pos":25,"tab":["tensorflow"],"id":"NgypN01Y0kLH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597557923942,"user_tz":420,"elapsed":787,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["initializer = tf.initializers.RandomNormal(stddev=0.01)\n","net = tf.keras.Sequential()\n","#kernel_initializer initializes the weight matrix and is passed to Dense\n","net.add(tf.keras.layers.Dense(1, kernel_initializer=initializer))"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":28,"tab":["tensorflow"],"id":"xGr5UeNf0kLJ","colab_type":"text"},"source":["The code above may look straightforward but you should note\n","that something strange is happening here.\n","We are initializing parameters for a network\n","even though Keras does not yet know\n","how many dimensions the input will have!\n","It might be 2 as in our example or it might be 2000.\n","Keras lets us get away with this because behind the scenes,\n","the initialization is actually *deferred*.\n","The real initialization will take place only\n","when we for the first time attempt to pass data through the network.\n","Just be careful to remember that since the parameters\n","have not been initialized yet,\n","we cannot access or manipulate them.\n"]},{"cell_type":"markdown","metadata":{"origin_pos":29,"id":"daJsm3O_0kLJ","colab_type":"text"},"source":["## Defining the Loss Function\n"]},{"cell_type":"markdown","metadata":{"origin_pos":32,"tab":["tensorflow"],"id":"KpRe7F3c0kLK","colab_type":"text"},"source":["The `MeanSquaredError` class computes the mean squared error, also known as squared $L_2$ norm.\n","By default it returns the average loss over examples.\n"]},{"cell_type":"code","metadata":{"origin_pos":35,"tab":["tensorflow"],"id":"1n5WIpdw0kLK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597557987375,"user_tz":420,"elapsed":761,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["loss = tf.keras.losses.MeanSquaredError()"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":36,"id":"8iqRO6uB0kLM","colab_type":"text"},"source":["## Defining the Optimization Algorithm\n"]},{"cell_type":"markdown","metadata":{"origin_pos":39,"tab":["tensorflow"],"id":"twI5TvLp0kLO","colab_type":"text"},"source":["Minibatch stochastic gradient descent is a standard tool\n","for optimizing neural networks\n","and thus Keras supports it alongside a number of\n","variations on this algorithm in the `optimizers` module.\n","Minibatch stochastic gradient descent just requires that\n","we set the value `learning_rate`, which is set to 0.03 here.\n"]},{"cell_type":"code","metadata":{"origin_pos":42,"tab":["tensorflow"],"id":"DgNOEP5B0kLO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597558496906,"user_tz":420,"elapsed":790,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}}},"source":["#This takes the current weights and bias vectors (of randomly selected rows of data) and \n","#then calculates w = w - lr*dw/batch_size\n","#similar for bias\n","trainer = tf.keras.optimizers.SGD(learning_rate=0.03)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":43,"id":"N68pc9X70kLT","colab_type":"text"},"source":["## Training\n","\n","You might have noticed that expressing our model through\n","high-level APIs of a deep learning framework\n","requires comparatively few lines of code.\n","We did not have to individually allocate parameters,\n","define our loss function, or implement minibatch stochastic gradient descent.\n","Once we start working with much more complex models,\n","advantages of high-level APIs will grow considerably.\n","However, once we have all the basic pieces in place,\n","the training loop itself is strikingly similar\n","to what we did when implementing everything from scratch.\n","\n","To refresh your memory: for some number of epochs,\n","we will make a complete pass over the dataset (`train_data`),\n","iteratively grabbing one minibatch of inputs\n","and the corresponding ground-truth labels.\n","For each minibatch, we go through the following ritual:\n","\n","* Generate predictions by calling `net(X)` and calculate the loss `l` (the forward propagation).\n","* Calculate gradients by running the backpropagation.\n","* Update the model parameters by invoking our optimizer.\n","\n","For good measure, we compute the loss after each epoch and print it to monitor progress.\n"]},{"cell_type":"code","metadata":{"origin_pos":46,"tab":["tensorflow"],"id":"yBJ-4sc30kLT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1597558823388,"user_tz":420,"elapsed":1844,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"8cad0505-a6ae-4f15-c405-69b1acf3c9f5"},"source":["num_epochs = 3\n","for epoch in range(num_epochs):\n","    for X, y in data_iter:\n","        with tf.GradientTape() as tape:\n","            #needed to calculate gradient\n","            l = loss(net(X, training=True), y)\n","        grads = tape.gradient(l, net.trainable_variables)\n","        trainer.apply_gradients(zip(grads, net.trainable_variables))\n","    #Average loss calculated over all the features data\n","    #only to monitor overall progress\n","    l = loss(net(features), labels)\n","    print(f'epoch {epoch + 1}, loss {l:f}')"],"execution_count":28,"outputs":[{"output_type":"stream","text":["epoch 1, loss 0.000178\n","epoch 2, loss 0.000103\n","epoch 3, loss 0.000101\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":47,"id":"ahCHXsQh0kLX","colab_type":"text"},"source":["Below, we compare the model parameters learned by training on finite data\n","and the actual parameters that generated our dataset.\n","To access parameters,\n","we first access the layer that we need from `net`\n","and then access that layer's weights and bias.\n","As in our from-scratch implementation,\n","note that our estimated parameters are\n","close to their ground-truth counterparts.\n"]},{"cell_type":"code","metadata":{"origin_pos":50,"tab":["tensorflow"],"id":"WD7pOVJQ0kLX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597558867524,"user_tz":420,"elapsed":779,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"a3b6ee32-2c7d-4b85-d5d3-55317e7a18a2"},"source":["w = net.get_weights()[0]\n","print('error in estimating w', true_w - tf.reshape(w, true_w.shape))\n","b = net.get_weights()[1]\n","print('error in estimating b', true_b - b)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["error in estimating w tf.Tensor([-0.00080657 -0.00029039], shape=(2,), dtype=float32)\n","error in estimating b [6.0081482e-05]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":51,"id":"iuRmQ73o0kLb","colab_type":"text"},"source":["## Summary\n"]},{"cell_type":"markdown","metadata":{"origin_pos":54,"tab":["tensorflow"],"id":"EdBihPce0kLb","colab_type":"text"},"source":["* Using TensorFlow's high-level APIs, we can implement models much more concisely.\n","* In TensorFlow, the `data` module provides tools for data processing, the `keras` module defines a large number of neural network layers and common loss functions.\n","* TensorFlow's module `initializers` provides various methods for model parameter initialization.\n","* Dimensionality and storage are automatically inferred (but be careful not to attempt to access parameters before they have been initialized).\n"]},{"cell_type":"markdown","metadata":{"origin_pos":55,"id":"OdNlF-Qa0kLc","colab_type":"text"},"source":["## Exercises\n"]},{"cell_type":"markdown","metadata":{"origin_pos":58,"tab":["tensorflow"],"id":"tdgQs6nN0kLc","colab_type":"text"},"source":["1. Review the TensorFlow documentation to see what loss functions and initialization methods are provided. Replace the loss by Huber's loss.\n","\n","[Discussions](https://discuss.d2l.ai/t/204)\n"]}]}