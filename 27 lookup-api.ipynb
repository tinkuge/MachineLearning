{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"27 lookup-api.ipynb","provenance":[{"file_id":"https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/chapter_preliminaries/lookup-api.ipynb","timestamp":1596167280799}]}},"cells":[{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"2P16iQpL-7wM","colab_type":"text"},"source":["# Documentation\n","\n","Due to constraints on the length of this book, we cannot possibly introduce every single Tensorflow function and class (and you probably would not want us to). The API documentation and additional tutorials and examples provide plenty of documentation beyond the book. In this section we provide you with some guidance to exploring the TensorFlow API.\n","\n","## Finding All the Functions and Classes in a Module\n","\n","In order to know which functions and classes can be called in a module, we\n","invoke the `dir` function. For instance, we can query all properties in the\n","module for generating random numbers:\n"]},{"cell_type":"code","metadata":{"attributes":{"classes":[],"id":"","n":"1"},"origin_pos":3,"tab":["tensorflow"],"id":"cb6GYfwc-7wN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596167403348,"user_tz":420,"elapsed":2103,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"be0b9a1d-10ac-41d8-c31a-38163f998d3f"},"source":["import tensorflow as tf\n","print(dir(tf.random))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["['Algorithm', 'Generator', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_sys', 'all_candidate_sampler', 'categorical', 'create_rng_state', 'experimental', 'fixed_unigram_candidate_sampler', 'gamma', 'get_global_generator', 'learned_unigram_candidate_sampler', 'log_uniform_candidate_sampler', 'normal', 'poisson', 'set_global_generator', 'set_seed', 'shuffle', 'stateless_binomial', 'stateless_categorical', 'stateless_gamma', 'stateless_normal', 'stateless_poisson', 'stateless_truncated_normal', 'stateless_uniform', 'truncated_normal', 'uniform', 'uniform_candidate_sampler']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":4,"id":"sygZUPYy-7wS","colab_type":"text"},"source":["Generally, we can ignore functions that start and end with `__` (special objects in Python) or functions that start with a single `_`(usually internal functions). Based on the remaining function or attribute names, we might hazard a guess that this module offers various methods for generating random numbers, including sampling from the uniform distribution (`uniform`), normal distribution (`normal`), and multinomial distribution  (`multinomial`).\n","\n","## Finding the Usage of Specific Functions and Classes\n","\n","For more specific instructions on how to use a given function or class, we can invoke the  `help` function. As an example, let us explore the usage instructions for tensors' `ones` function.\n"]},{"cell_type":"code","metadata":{"origin_pos":7,"tab":["tensorflow"],"id":"oZvEK7F0-7wS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"ok","timestamp":1596167582546,"user_tz":420,"elapsed":328,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"0357cb97-4dbe-47d7-db78-5c28356084d5"},"source":["help(tf.ones)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Help on function ones in module tensorflow.python.ops.array_ops:\n","\n","ones(shape, dtype=tf.float32, name=None)\n","    Creates a tensor with all elements set to one (1).\n","    \n","    See also `tf.ones_like`.\n","    \n","    This operation returns a tensor of type `dtype` with shape `shape` and\n","    all elements set to one.\n","    \n","    >>> tf.ones([3, 4], tf.int32)\n","    <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n","    array([[1, 1, 1, 1],\n","           [1, 1, 1, 1],\n","           [1, 1, 1, 1]], dtype=int32)>\n","    \n","    Args:\n","      shape: A `list` of integers, a `tuple` of integers, or\n","        a 1-D `Tensor` of type `int32`.\n","      dtype: Optional DType of an element in the resulting `Tensor`. Default is\n","        `tf.float32`.\n","      name: Optional string. A name for the operation.\n","    \n","    Returns:\n","      A `Tensor` with all elements set to one (1).\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":8,"id":"fA4bD2HY-7wV","colab_type":"text"},"source":["From the documentation, we can see that the `ones` function creates a new tensor with the specified shape and sets all the elements to the value of 1. Whenever possible, you should run a quick test to confirm your interpretation:\n"]},{"cell_type":"code","metadata":{"origin_pos":11,"tab":["tensorflow"],"id":"mgcwoymk-7wV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596167650624,"user_tz":420,"elapsed":515,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"b16392ec-fc61-4a0f-dc90-a97a156a2615"},"source":["tf.ones(4)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"origin_pos":12,"id":"5Tjt9eHF-7wY","colab_type":"text"},"source":["In the Jupyter notebook, we can use `?` to display the document in another\n","window. For example, `list?` will create content that is almost\n","identical to `help(list)`, displaying it in a new browser\n","window. In addition, if we use two question marks, such as\n","`list??`, the Python code implementing the function will also be\n","displayed.\n","\n","\n","## Summary\n","\n","* The official documentation provides plenty of descriptions and examples that are beyond this book.\n","* We can look up documentation for the usage of an API by calling the `dir` and `help` functions, or `?` and `??` in Jupyter notebooks.\n","\n","\n","## Exercises\n","\n","1. Look up the documentation for any function or class in the deep learning framework. Can you also find the documentation on the official website of the framework?\n"]},{"cell_type":"code","metadata":{"id":"aPklL4KpAcVJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596167762481,"user_tz":420,"elapsed":973,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"62fbb381-9e23-46dd-b53c-a5754187aba1"},"source":["import tensorflow_probability as tfp\n","print(dir(tfp))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'bijectors', 'debugging', 'distributions', 'edward2', 'experimental', 'glm', 'layers', 'math', 'mcmc', 'monte_carlo', 'optimizer', 'python', 'stats', 'sts', 'util', 'vi']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gaFMFkBQBA5R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596167839676,"user_tz":420,"elapsed":316,"user":{"displayName":"Dinakar Geddapu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcRIoVExYcdvhSOVBJo3iiy9SWT0WI6bFoIcBHqA=s64","userId":"05110836538322591722"}},"outputId":"c404bf4a-5dbe-48a5-ce00-d5dd492e8a63"},"source":["help(tfp.distributions.sample)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Help on module tensorflow_probability.python.distributions.sample in tensorflow_probability.python.distributions:\n","\n","NAME\n","    tensorflow_probability.python.distributions.sample - The Sample distribution class.\n","\n","CLASSES\n","    tensorflow_probability.python.distributions.distribution.Distribution(tensorflow_probability.python.distributions.distribution._BaseDistribution)\n","        Sample\n","    \n","    class Sample(tensorflow_probability.python.distributions.distribution.Distribution)\n","     |  Sample distribution via independent draws.\n","     |  \n","     |  This distribution is useful for reducing over a collection of independent,\n","     |  identical draws. It is otherwise identical to the input distribution.\n","     |  \n","     |  #### Mathematical Details\n","     |  \n","     |  The probability function is,\n","     |  \n","     |  ```none\n","     |  p(x) = prod{ p(x[i]) : i = 0, ..., (n - 1) }\n","     |  ```\n","     |  \n","     |  #### Examples\n","     |  \n","     |  ```python\n","     |  tfd = tfp.distributions\n","     |  \n","     |  # Example 1: Five scalar draws.\n","     |  \n","     |  s = tfd.Sample(\n","     |      tfd.Normal(loc=0, scale=1),\n","     |      sample_shape=5)\n","     |  x = s.sample()\n","     |  # ==> x.shape: [5]\n","     |  \n","     |  lp = s.log_prob(x)\n","     |  # ==> lp.shape: []\n","     |  #     Equivalently: tf.reduce_sum(s.distribution.log_prob(x), axis=[0, 1])\n","     |  #\n","     |  # `Sample.log_prob` computes the per-{sample, batch} `log_prob`s then sums\n","     |  # over the `Sample.sample_shape` dimensions. In the above example `log_prob`\n","     |  # dims `[0, 1]` are summed out. Conceptually, first dim `1` is summed (this\n","     |  # being the intrinsic `event`) then we sum over `Sample.sample_shape` dims, in\n","     |  # this case dim `0`.\n","     |  \n","     |  # Example 2: `[5, 4]`-draws of a bivariate Normal.\n","     |  \n","     |  s = tfd.Sample(\n","     |      tfd.Independent(tfd.Normal(loc=tf.zeros([3, 2]), scale=1),\n","     |                      reinterpreted_batch_ndims=1),\n","     |      sample_shape=[5, 4])\n","     |  x = s.sample([6, 1])\n","     |  # ==> x.shape: [6, 1, 3, 5, 4, 2]\n","     |  \n","     |  lp = s.log_prob(x)\n","     |  # ==> lp.shape: [6, 1, 3]\n","     |  #\n","     |  # `s.log_prob` will reduce over (intrinsic) event dims, i.e., dim `5`, then\n","     |  # sums over `s.sample_shape` dims `[3, 4]` corresponding to shape (slice)\n","     |  # `[5, 4]`.\n","     |  ```\n","     |  \n","     |  Method resolution order:\n","     |      Sample\n","     |      tensorflow_probability.python.distributions.distribution.Distribution\n","     |      tensorflow_probability.python.distributions.distribution._BaseDistribution\n","     |      tensorflow.python.module.module.Module\n","     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n","     |      tensorflow.python.training.tracking.base.Trackable\n","     |      builtins.object\n","     |  \n","     |  Methods defined here:\n","     |  \n","     |  __init__(self, distribution, sample_shape=(), validate_args=False, name=None)\n","     |      Construct the `Sample` distribution.\n","     |      \n","     |      Args:\n","     |        distribution: The base distribution instance to transform. Typically an\n","     |          instance of `Distribution`.\n","     |        sample_shape: `int` scalar or vector `Tensor` representing the shape of a\n","     |          single sample.\n","     |        validate_args: Python `bool`.  Whether to validate input with asserts.\n","     |          If `validate_args` is `False`, and the inputs are invalid,\n","     |          correct behavior is not guaranteed.\n","     |        name: The name for ops managed by the distribution.\n","     |          Default value: `None` (i.e., `'Sample' + distribution.name`).\n","     |  \n","     |  cross_entropy(self, other, name='cross_entropy')\n","     |      Computes the (Shannon) cross entropy.\n","     |      \n","     |      Denote this distribution (`self`) by `P` and the `other` distribution by\n","     |      `Q`. Assuming `P, Q` are absolutely continuous with respect to\n","     |      one another and permit densities `p(x) dr(x)` and `q(x) dr(x)`, (Shannon)\n","     |      cross entropy is defined as:\n","     |      \n","     |      ```none\n","     |      H[P, Q] = E_p[-log q(X)] = -int_F p(x) log q(x) dr(x)\n","     |      ```\n","     |      \n","     |      where `F` denotes the support of the random variable `X ~ P`.\n","     |      \n","     |      `other` types with built-in registrations: `Sample`\n","     |      \n","     |      Args:\n","     |        other: `tfp.distributions.Distribution` instance.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |      \n","     |      Returns:\n","     |        cross_entropy: `self.dtype` `Tensor` with shape `[B1, ..., Bn]`\n","     |          representing `n` different calculations of (Shannon) cross entropy.\n","     |  \n","     |  kl_divergence(self, other, name='kl_divergence')\n","     |      Computes the Kullback--Leibler divergence.\n","     |      \n","     |      Denote this distribution (`self`) by `p` and the `other` distribution by\n","     |      `q`. Assuming `p, q` are absolutely continuous with respect to reference\n","     |      measure `r`, the KL divergence is defined as:\n","     |      \n","     |      ```none\n","     |      KL[p, q] = E_p[log(p(X)/q(X))]\n","     |               = -int_F p(x) log q(x) dr(x) + int_F p(x) log p(x) dr(x)\n","     |               = H[p, q] - H[p]\n","     |      ```\n","     |      \n","     |      where `F` denotes the support of the random variable `X ~ p`, `H[., .]`\n","     |      denotes (Shannon) cross entropy, and `H[.]` denotes (Shannon) entropy.\n","     |      \n","     |      `other` types with built-in registrations: `Sample`\n","     |      \n","     |      Args:\n","     |        other: `tfp.distributions.Distribution` instance.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |      \n","     |      Returns:\n","     |        kl_divergence: `self.dtype` `Tensor` with shape `[B1, ..., Bn]`\n","     |          representing `n` different calculations of the Kullback-Leibler\n","     |          divergence.\n","     |  \n","     |  mean(self, name='mean', **kwargs)\n","     |      Mean.\n","     |      \n","     |      Additional documentation from `Sample`:\n","     |      \n","     |      Implements summary statistic, eg, mean, stddev, mode.\n","     |  \n","     |  mode(self, name='mode', **kwargs)\n","     |      Mode.\n","     |      \n","     |      Additional documentation from `Sample`:\n","     |      \n","     |      Implements summary statistic, eg, mean, stddev, mode.\n","     |  \n","     |  stddev(self, name='stddev', **kwargs)\n","     |      Standard deviation.\n","     |      \n","     |      Standard deviation is defined as,\n","     |      \n","     |      ```none\n","     |      stddev = E[(X - E[X])**2]**0.5\n","     |      ```\n","     |      \n","     |      where `X` is the random variable associated with this distribution, `E`\n","     |      denotes expectation, and `stddev.shape = batch_shape + event_shape`.\n","     |      \n","     |      \n","     |      Additional documentation from `Sample`:\n","     |      \n","     |      Implements summary statistic, eg, mean, stddev, mode.\n","     |      \n","     |      Args:\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        stddev: Floating-point `Tensor` with shape identical to\n","     |          `batch_shape + event_shape`, i.e., the same shape as `self.mean()`.\n","     |  \n","     |  variance(self, name='variance', **kwargs)\n","     |      Variance.\n","     |      \n","     |      Variance is defined as,\n","     |      \n","     |      ```none\n","     |      Var = E[(X - E[X])**2]\n","     |      ```\n","     |      \n","     |      where `X` is the random variable associated with this distribution, `E`\n","     |      denotes expectation, and `Var.shape = batch_shape + event_shape`.\n","     |      \n","     |      \n","     |      Additional documentation from `Sample`:\n","     |      \n","     |      Implements summary statistic, eg, mean, stddev, mode.\n","     |      \n","     |      Args:\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        variance: Floating-point `Tensor` with shape identical to\n","     |          `batch_shape + event_shape`, i.e., the same shape as `self.mean()`.\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Data descriptors defined here:\n","     |  \n","     |  distribution\n","     |  \n","     |  sample_shape\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Data and other attributes defined here:\n","     |  \n","     |  __abstractmethods__ = frozenset()\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Methods inherited from tensorflow_probability.python.distributions.distribution.Distribution:\n","     |  \n","     |  __getitem__(self, slices)\n","     |      Slices the batch axes of this distribution, returning a new instance.\n","     |      \n","     |      ```python\n","     |      b = tfd.Bernoulli(logits=tf.zeros([3, 5, 7, 9]))\n","     |      b.batch_shape  # => [3, 5, 7, 9]\n","     |      b2 = b[:, tf.newaxis, ..., -2:, 1::2]\n","     |      b2.batch_shape  # => [3, 1, 5, 2, 4]\n","     |      \n","     |      x = tf.random.normal([5, 3, 2, 2])\n","     |      cov = tf.matmul(x, x, transpose_b=True)\n","     |      chol = tf.cholesky(cov)\n","     |      loc = tf.random.normal([4, 1, 3, 1])\n","     |      mvn = tfd.MultivariateNormalTriL(loc, chol)\n","     |      mvn.batch_shape  # => [4, 5, 3]\n","     |      mvn.event_shape  # => [2]\n","     |      mvn2 = mvn[:, 3:, ..., ::-1, tf.newaxis]\n","     |      mvn2.batch_shape  # => [4, 2, 3, 1]\n","     |      mvn2.event_shape  # => [2]\n","     |      ```\n","     |      \n","     |      Args:\n","     |        slices: slices from the [] operator\n","     |      \n","     |      Returns:\n","     |        dist: A new `tfd.Distribution` instance with sliced parameters.\n","     |  \n","     |  __iter__(self)\n","     |  \n","     |  __repr__(self)\n","     |      Return repr(self).\n","     |  \n","     |  __str__(self)\n","     |      Return str(self).\n","     |  \n","     |  batch_shape_tensor(self, name='batch_shape_tensor')\n","     |      Shape of a single sample from a single event index as a 1-D `Tensor`.\n","     |      \n","     |      The batch dimensions are indexes into independent, non-identical\n","     |      parameterizations of this distribution.\n","     |      \n","     |      Args:\n","     |        name: name to give to the op\n","     |      \n","     |      Returns:\n","     |        batch_shape: `Tensor`.\n","     |  \n","     |  cdf(self, value, name='cdf', **kwargs)\n","     |      Cumulative distribution function.\n","     |      \n","     |      Given random variable `X`, the cumulative distribution function `cdf` is:\n","     |      \n","     |      ```none\n","     |      cdf(x) := P[X <= x]\n","     |      ```\n","     |      \n","     |      Args:\n","     |        value: `float` or `double` `Tensor`.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        cdf: a `Tensor` of shape `sample_shape(x) + self.batch_shape` with\n","     |          values of type `self.dtype`.\n","     |  \n","     |  copy(self, **override_parameters_kwargs)\n","     |      Creates a deep copy of the distribution.\n","     |      \n","     |      Note: the copy distribution may continue to depend on the original\n","     |      initialization arguments.\n","     |      \n","     |      Args:\n","     |        **override_parameters_kwargs: String/value dictionary of initialization\n","     |          arguments to override with new values.\n","     |      \n","     |      Returns:\n","     |        distribution: A new instance of `type(self)` initialized from the union\n","     |          of self.parameters and override_parameters_kwargs, i.e.,\n","     |          `dict(self.parameters, **override_parameters_kwargs)`.\n","     |  \n","     |  covariance(self, name='covariance', **kwargs)\n","     |      Covariance.\n","     |      \n","     |      Covariance is (possibly) defined only for non-scalar-event distributions.\n","     |      \n","     |      For example, for a length-`k`, vector-valued distribution, it is calculated\n","     |      as,\n","     |      \n","     |      ```none\n","     |      Cov[i, j] = Covariance(X_i, X_j) = E[(X_i - E[X_i]) (X_j - E[X_j])]\n","     |      ```\n","     |      \n","     |      where `Cov` is a (batch of) `k x k` matrix, `0 <= (i, j) < k`, and `E`\n","     |      denotes expectation.\n","     |      \n","     |      Alternatively, for non-vector, multivariate distributions (e.g.,\n","     |      matrix-valued, Wishart), `Covariance` shall return a (batch of) matrices\n","     |      under some vectorization of the events, i.e.,\n","     |      \n","     |      ```none\n","     |      Cov[i, j] = Covariance(Vec(X)_i, Vec(X)_j) = [as above]\n","     |      ```\n","     |      \n","     |      where `Cov` is a (batch of) `k' x k'` matrices,\n","     |      `0 <= (i, j) < k' = reduce_prod(event_shape)`, and `Vec` is some function\n","     |      mapping indices of this distribution's event dimensions to indices of a\n","     |      length-`k'` vector.\n","     |      \n","     |      Args:\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        covariance: Floating-point `Tensor` with shape `[B1, ..., Bn, k', k']`\n","     |          where the first `n` dimensions are batch coordinates and\n","     |          `k' = reduce_prod(self.event_shape)`.\n","     |  \n","     |  entropy(self, name='entropy', **kwargs)\n","     |      Shannon entropy in nats.\n","     |  \n","     |  event_shape_tensor(self, name='event_shape_tensor')\n","     |      Shape of a single sample from a single batch as a 1-D int32 `Tensor`.\n","     |      \n","     |      Args:\n","     |        name: name to give to the op\n","     |      \n","     |      Returns:\n","     |        event_shape: `Tensor`.\n","     |  \n","     |  is_scalar_batch(self, name='is_scalar_batch')\n","     |      Indicates that `batch_shape == []`.\n","     |      \n","     |      Args:\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |      \n","     |      Returns:\n","     |        is_scalar_batch: `bool` scalar `Tensor`.\n","     |  \n","     |  is_scalar_event(self, name='is_scalar_event')\n","     |      Indicates that `event_shape == []`.\n","     |      \n","     |      Args:\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |      \n","     |      Returns:\n","     |        is_scalar_event: `bool` scalar `Tensor`.\n","     |  \n","     |  log_cdf(self, value, name='log_cdf', **kwargs)\n","     |      Log cumulative distribution function.\n","     |      \n","     |      Given random variable `X`, the cumulative distribution function `cdf` is:\n","     |      \n","     |      ```none\n","     |      log_cdf(x) := Log[ P[X <= x] ]\n","     |      ```\n","     |      \n","     |      Often, a numerical approximation can be used for `log_cdf(x)` that yields\n","     |      a more accurate answer than simply taking the logarithm of the `cdf` when\n","     |      `x << -1`.\n","     |      \n","     |      Args:\n","     |        value: `float` or `double` `Tensor`.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        logcdf: a `Tensor` of shape `sample_shape(x) + self.batch_shape` with\n","     |          values of type `self.dtype`.\n","     |  \n","     |  log_prob(self, value, name='log_prob', **kwargs)\n","     |      Log probability density/mass function.\n","     |      \n","     |      Args:\n","     |        value: `float` or `double` `Tensor`.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        log_prob: a `Tensor` of shape `sample_shape(x) + self.batch_shape` with\n","     |          values of type `self.dtype`.\n","     |  \n","     |  log_survival_function(self, value, name='log_survival_function', **kwargs)\n","     |      Log survival function.\n","     |      \n","     |      Given random variable `X`, the survival function is defined:\n","     |      \n","     |      ```none\n","     |      log_survival_function(x) = Log[ P[X > x] ]\n","     |                               = Log[ 1 - P[X <= x] ]\n","     |                               = Log[ 1 - cdf(x) ]\n","     |      ```\n","     |      \n","     |      Typically, different numerical approximations can be used for the log\n","     |      survival function, which are more accurate than `1 - cdf(x)` when `x >> 1`.\n","     |      \n","     |      Args:\n","     |        value: `float` or `double` `Tensor`.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        `Tensor` of shape `sample_shape(x) + self.batch_shape` with values of type\n","     |          `self.dtype`.\n","     |  \n","     |  prob(self, value, name='prob', **kwargs)\n","     |      Probability density/mass function.\n","     |      \n","     |      Args:\n","     |        value: `float` or `double` `Tensor`.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        prob: a `Tensor` of shape `sample_shape(x) + self.batch_shape` with\n","     |          values of type `self.dtype`.\n","     |  \n","     |  quantile(self, value, name='quantile', **kwargs)\n","     |      Quantile function. Aka 'inverse cdf' or 'percent point function'.\n","     |      \n","     |      Given random variable `X` and `p in [0, 1]`, the `quantile` is:\n","     |      \n","     |      ```none\n","     |      quantile(p) := x such that P[X <= x] == p\n","     |      ```\n","     |      \n","     |      Args:\n","     |        value: `float` or `double` `Tensor`.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        quantile: a `Tensor` of shape `sample_shape(x) + self.batch_shape` with\n","     |          values of type `self.dtype`.\n","     |  \n","     |  sample(self, sample_shape=(), seed=None, name='sample', **kwargs)\n","     |      Generate samples of the specified shape.\n","     |      \n","     |      Note that a call to `sample()` without arguments will generate a single\n","     |      sample.\n","     |      \n","     |      Args:\n","     |        sample_shape: 0D or 1D `int32` `Tensor`. Shape of the generated samples.\n","     |        seed: Python integer or `tfp.util.SeedStream` instance, for seeding PRNG.\n","     |        name: name to give to the op.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        samples: a `Tensor` with prepended dimensions `sample_shape`.\n","     |  \n","     |  survival_function(self, value, name='survival_function', **kwargs)\n","     |      Survival function.\n","     |      \n","     |      Given random variable `X`, the survival function is defined:\n","     |      \n","     |      ```none\n","     |      survival_function(x) = P[X > x]\n","     |                           = 1 - P[X <= x]\n","     |                           = 1 - cdf(x).\n","     |      ```\n","     |      \n","     |      Args:\n","     |        value: `float` or `double` `Tensor`.\n","     |        name: Python `str` prepended to names of ops created by this function.\n","     |        **kwargs: Named arguments forwarded to subclass implementation.\n","     |      \n","     |      Returns:\n","     |        `Tensor` of shape `sample_shape(x) + self.batch_shape` with values of type\n","     |          `self.dtype`.\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Class methods inherited from tensorflow_probability.python.distributions.distribution.Distribution:\n","     |  \n","     |  param_shapes(sample_shape, name='DistributionParamShapes') from tensorflow_probability.python.distributions.distribution._DistributionMeta\n","     |      Shapes of parameters given the desired shape of a call to `sample()`.\n","     |      \n","     |      This is a class method that describes what key/value arguments are required\n","     |      to instantiate the given `Distribution` so that a particular shape is\n","     |      returned for that instance's call to `sample()`.\n","     |      \n","     |      Subclasses should override class method `_param_shapes`.\n","     |      \n","     |      Args:\n","     |        sample_shape: `Tensor` or python list/tuple. Desired shape of a call to\n","     |          `sample()`.\n","     |        name: name to prepend ops with.\n","     |      \n","     |      Returns:\n","     |        `dict` of parameter name to `Tensor` shapes.\n","     |  \n","     |  param_static_shapes(sample_shape) from tensorflow_probability.python.distributions.distribution._DistributionMeta\n","     |      param_shapes with static (i.e. `TensorShape`) shapes.\n","     |      \n","     |      This is a class method that describes what key/value arguments are required\n","     |      to instantiate the given `Distribution` so that a particular shape is\n","     |      returned for that instance's call to `sample()`. Assumes that the sample's\n","     |      shape is known statically.\n","     |      \n","     |      Subclasses should override class method `_param_shapes` to return\n","     |      constant-valued tensors when constant values are fed.\n","     |      \n","     |      Args:\n","     |        sample_shape: `TensorShape` or python list/tuple. Desired shape of a call\n","     |          to `sample()`.\n","     |      \n","     |      Returns:\n","     |        `dict` of parameter name to `TensorShape`.\n","     |      \n","     |      Raises:\n","     |        ValueError: if `sample_shape` is a `TensorShape` and is not fully defined.\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Data descriptors inherited from tensorflow_probability.python.distributions.distribution.Distribution:\n","     |  \n","     |  allow_nan_stats\n","     |      Python `bool` describing behavior when a stat is undefined.\n","     |      \n","     |      Stats return +/- infinity when it makes sense. E.g., the variance of a\n","     |      Cauchy distribution is infinity. However, sometimes the statistic is\n","     |      undefined, e.g., if a distribution's pdf does not achieve a maximum within\n","     |      the support of the distribution, the mode is undefined. If the mean is\n","     |      undefined, then by definition the variance is undefined. E.g. the mean for\n","     |      Student's T for df = 1 is undefined (no clear way to say it is either + or -\n","     |      infinity), so the variance = E[(X - mean)**2] is also undefined.\n","     |      \n","     |      Returns:\n","     |        allow_nan_stats: Python `bool`.\n","     |  \n","     |  batch_shape\n","     |      Shape of a single sample from a single event index as a `TensorShape`.\n","     |      \n","     |      May be partially defined or unknown.\n","     |      \n","     |      The batch dimensions are indexes into independent, non-identical\n","     |      parameterizations of this distribution.\n","     |      \n","     |      Returns:\n","     |        batch_shape: `TensorShape`, possibly unknown.\n","     |  \n","     |  dtype\n","     |      The `DType` of `Tensor`s handled by this `Distribution`.\n","     |  \n","     |  event_shape\n","     |      Shape of a single sample from a single batch as a `TensorShape`.\n","     |      \n","     |      May be partially defined or unknown.\n","     |      \n","     |      Returns:\n","     |        event_shape: `TensorShape`, possibly unknown.\n","     |  \n","     |  name\n","     |      Name prepended to all ops created by this `Distribution`.\n","     |  \n","     |  parameters\n","     |      Dictionary of parameters used to instantiate this `Distribution`.\n","     |  \n","     |  reparameterization_type\n","     |      Describes how samples from the distribution are reparameterized.\n","     |      \n","     |      Currently this is one of the static instances\n","     |      `tfd.FULLY_REPARAMETERIZED` or `tfd.NOT_REPARAMETERIZED`.\n","     |      \n","     |      Returns:\n","     |        An instance of `ReparameterizationType`.\n","     |  \n","     |  validate_args\n","     |      Python `bool` indicating possibly expensive checks are enabled.\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Class methods inherited from tensorflow.python.module.module.Module:\n","     |  \n","     |  with_name_scope(method) from tensorflow_probability.python.distributions.distribution._DistributionMeta\n","     |      Decorator to automatically enter the module name scope.\n","     |      \n","     |      >>> class MyModule(tf.Module):\n","     |      ...   @tf.Module.with_name_scope\n","     |      ...   def __call__(self, x):\n","     |      ...     if not hasattr(self, 'w'):\n","     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n","     |      ...     return tf.matmul(x, self.w)\n","     |      \n","     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n","     |      names included the module name:\n","     |      \n","     |      >>> mod = MyModule()\n","     |      >>> mod(tf.ones([1, 2]))\n","     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n","     |      >>> mod.w\n","     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n","     |      numpy=..., dtype=float32)>\n","     |      \n","     |      Args:\n","     |        method: The method to wrap.\n","     |      \n","     |      Returns:\n","     |        The original method wrapped such that it enters the module's name scope.\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Data descriptors inherited from tensorflow.python.module.module.Module:\n","     |  \n","     |  name_scope\n","     |      Returns a `tf.name_scope` instance for this class.\n","     |  \n","     |  submodules\n","     |      Sequence of all sub-modules.\n","     |      \n","     |      Submodules are modules which are properties of this module, or found as\n","     |      properties of modules which are properties of this module (and so on).\n","     |      \n","     |      >>> a = tf.Module()\n","     |      >>> b = tf.Module()\n","     |      >>> c = tf.Module()\n","     |      >>> a.b = b\n","     |      >>> b.c = c\n","     |      >>> list(a.submodules) == [b, c]\n","     |      True\n","     |      >>> list(b.submodules) == [c]\n","     |      True\n","     |      >>> list(c.submodules) == []\n","     |      True\n","     |      \n","     |      Returns:\n","     |        A sequence of all submodules.\n","     |  \n","     |  trainable_variables\n","     |      Sequence of trainable variables owned by this module and its submodules.\n","     |      \n","     |      Note: this method uses reflection to find variables on the current instance\n","     |      and submodules. For performance reasons you may wish to cache the result\n","     |      of calling this method if you don't expect the return value to change.\n","     |      \n","     |      Returns:\n","     |        A sequence of variables for the current module (sorted by attribute\n","     |        name) followed by variables from all submodules recursively (breadth\n","     |        first).\n","     |  \n","     |  variables\n","     |      Sequence of variables owned by this module and its submodules.\n","     |      \n","     |      Note: this method uses reflection to find variables on the current instance\n","     |      and submodules. For performance reasons you may wish to cache the result\n","     |      of calling this method if you don't expect the return value to change.\n","     |      \n","     |      Returns:\n","     |        A sequence of variables for the current module (sorted by attribute\n","     |        name) followed by variables from all submodules recursively (breadth\n","     |        first).\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n","     |  \n","     |  __delattr__(self, name)\n","     |      Implement delattr(self, name).\n","     |  \n","     |  __setattr__(self, name, value)\n","     |      Support self.foo = trackable syntax.\n","     |  \n","     |  ----------------------------------------------------------------------\n","     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n","     |  \n","     |  __dict__\n","     |      dictionary for instance variables (if defined)\n","     |  \n","     |  __weakref__\n","     |      list of weak references to the object (if defined)\n","\n","DATA\n","    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n","    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n","    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n","\n","FILE\n","    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/distributions/sample.py\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":15,"tab":["tensorflow"],"id":"_-LXS_9t-7wY","colab_type":"text"},"source":["[Discussions](https://discuss.d2l.ai/t/199)\n"]}]}